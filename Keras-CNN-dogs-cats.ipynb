{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import HTML\n",
    "# import urllib3\n",
    "# HTML(urllib3.url('/Users/mahsa/OneDrive/Desktop/ML-projects/dogs-cats/style.css').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Tutorial blog, we will learn the basics of Convolutional Neural Networks (CNNs) and how to use them in Keras for the binary classification of dogs and cats images provided by <a href=\"https://www.kaggle.com/c/dogs-vs-cats/data\">kaggle</a>. \n",
    "\n",
    "Why Keras? Keras is an open source neural network library that can be run on top of machine learning libraries such as Tensorflow or Theano. With Keras, you can wrtie high level code to bulid neural networks in just a few lines and Keras engine would covert the code to tensorflow or Theano code. Keras makes it very fast and easy to make protorypes and ready solutions while learning Tensrflow helps you understand the underlying sturcutre. \n",
    "\n",
    "For this project We will be using Keras with the Tenslorflow backend os before installing Keras, you need to install Tensorflow in your environmen first.\n",
    "\n",
    "<h3>Importing Liberaries</h3>\n",
    "\n",
    "So let's first import the python liberaries. As usual we have pandas for data wrangling. We will be using opencv for some image preprations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahsa\\AppData\\Local\\conda\\conda\\envs\\python3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Loading the data</h3>\n",
    "\n",
    "The train and test stes contain 25,000 and 12500 images of dogs and cats. So it would take some time to copy them on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/Users/mahsa/OneDrive/Desktop/ML-projects/dogs-cats/train/'\n",
    "test_path =  '/Users/mahsa/OneDrive/Desktop/ML-projects/dogs-cats/test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Pre-processing the images</h3>\n",
    "\n",
    "Before We move to making a training model with Keras, we need to prepare the images as the input data. The images in both train adn test sets are in different sizes and we need to specify the single input shape in Keras sequnetial model we are going to use in this project. So all the input images should have the same shape. One of the tools to do image preparation is Opencv and can be used in different languages such aS C++ and python. Also, the Keras image agumentation instance that we will going use gets inputs as numpy arrays (I will explain keras image generator later in the process).\n",
    "The function below uplaods and resizes each image to 200X200 and convert it to numpy array at the same time, then it stores the image array in a list (image_data). The function makes the labels list by going the list of image paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 128\n",
    "img_height = 128\n",
    "\n",
    "def label_img(img): \n",
    "    if 'dog.' in img: \n",
    "        return [0,1]                             \n",
    "    elif 'cat.' in img:\n",
    "        return [1,0]\n",
    "        \n",
    "def prepare_data(train_data_path):\n",
    "    image_data = []\n",
    "    for image_path in tqdm(train_data_path):\n",
    "        label = label_img(image_path)\n",
    "        img = cv2.resize(cv2.imread(image_path), (img_width,img_height), interpolation=cv2.INTER_CUBIC)\n",
    "        image_data.append([np.array(img),np.array(label)])\n",
    "    shuffle(image_data)\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18000/18000 [04:00<00:00, 75.00it/s]\n"
     ]
    }
   ],
   "source": [
    "train_images = [train_path + i for i in os.listdir(train_path)] \n",
    "#test_images = [test_path + i for i in os.listdir(test_path)]\n",
    "\n",
    "train_data = prepare_data(train_images[0:9000] + train_images[16000:25000])\n",
    "\n",
    "X = np.array([j[0] for j in train_data])\n",
    "Y = np.array([j[1] for j in train_data])\n",
    "\n",
    "#test_data = prepare_data(test_images)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(np.array(X), np.array(Y), test_size=0.2, random_state=121)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Image Augmentation</h4>\n",
    "\n",
    "https://keras.io/preprocessing/image/\n",
    "\n",
    "https://www.learnopencv.com/wp-content/uploads/2017/11/data-aug.png\n",
    "\n",
    "\n",
    "One of the major challenges in making a model is finding enough data to train and avoid overfitting. Data Augmentation is a  technique to combat overfitting and help the model generalize better. Using Data Agumentation process, you can artificially create altered versions of the existing images to expand the training data set. The alternations include methods such as rotation, shearing, zooming, shifting etc. In keras the Agumentation process is done by using ImageDataGenerator instance.you can find the full list of augumentation parameters in ImageDataGenerator <a href=\"https://keras.io/preprocessing/image/\">here</a>\n",
    "The Augumentation parametters we are going ot use here are: \n",
    "\n",
    "Rotation, Horizontal filip, zooming ad shearing. another transforamtion that can be done by ImageDataGenerator is rescaling. The RGB pixel data is between 0-255 and with rescaling we reduce them to the range 0-1 in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=60,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    "   )\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you include featurewise_center or featurewise_std_normalization or zca_whitening in your ImageDataGenerator configuring, you would need to fit it on your data (both train and validation sets). This will calculate the internal data stats (std, mean and principal components) for the data those transformations specified in agumnetation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_datagen.fit(X_train)\n",
    "# train_datagen.fit(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Generating data batches</h4>\n",
    "\n",
    "The next step is generating bacthes of images data and their labels for our network which is done by The datagen.flow(). This function takes the numpy and labels array and make batches of agumented data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_generator = train_datagen.flow(X_train, Y_train, batch_size=batch_size)\n",
    "validation_generator = val_datagen.flow(X_val, Y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Making the Network</h3> \n",
    "\n",
    "<h4>Sequential vs. Functional models</h4>\n",
    "\n",
    "There are two types models in Keras: functional and sequential. \n",
    "\n",
    "The sequential API allows you to design models layer by layer and connect each layer directly to the to the previous and next layers. You also need to specify only single input and outputs for the sequnetial models. \n",
    "\n",
    "On the othe hand, Functional API gives more felxibiltiy and allows to make deeper and more copmicated models and that are not squentional> Using functional API, you can connect layers to any other layer to make deeper models such as <a href=\"https://www.youtube.com/watch?v=K0uoBKBQ1gA\">Residual Networks</a>. In addition, you can have multiple inputs and outputs for your network. \n",
    "\n",
    "Here we are going to use Sequnetial API to make a basic network.\n",
    "\n",
    "The model is initialized by using Sequential() class. Now let's add layes to the model:\n",
    "\n",
    "<h4>Convolutional Neural Network</h4>\n",
    "\n",
    "\n",
    "For our image classifier model, we are going to a convolutional Neural Network as follow:\n",
    "\n",
    "convoluted layer => Maxpooling => convoluted layer => maxpooling => fully connected layer => output layer\n",
    "\n",
    "The model gets input as black and white 200X200 images, then convolutes and max pool the images in 2 sequnetial leyers. this is followed by a fully connceted layer and finally an output layer.\n",
    "\n",
    "We add the first layer which is convolutional layer with the input shape of 200 height by 200 width and the channel number of 3 since the images are colorful. \n",
    "\n",
    "For both convolutional and fully connected layers, we use relu (rectified linear unit) as our activation function (why)\n",
    "for this layer, I have chose the convolution window of 2X2 which will shift on the image data with the stride of 1X1 (). I will explain how convolutional and maxpooling work in details in another blog on using tensorflow classifer. You don't need to worry about the output size for the next layer which is a pooling layer and Keras will take care of calulation that.\n",
    "\n",
    "Now that we convoluted the image, the next step is pooling. Pooling reduces the dimensions of output features which makes computation faster. we add a maxpooling layer that has a 2X2 pixel window and pickes the max number in image data by sliding over the images by 2 pixel in height and width.\n",
    "\n",
    "Our model will consist of two Convolutional layers and two Maxppooling layers. After the first pooling layer, we double the number of input channels for the second convolutional layer(?). Afterwards, We flatten the output from the last maxpooling layer\n",
    "for the fully connected layer we are going to add. Unlinke Tensorflow, we do not need to figure the size of output tesnsor to fellaten and keras takes care of that. \n",
    "\n",
    "\n",
    "Now we have out flattened input data to passs through a fully connected layer. This layer can be created using Dense class in Keras and we specify the number of nodes for this layer 100. \n",
    "\n",
    "for the first two convolutional layers we are using Relu as activation and for our fully connected layer we will activate nodes by a softmax function. \n",
    "\n",
    "We finally add the last layer which is the output layer which its size is the number of our binary classes of cat and dog.\n",
    "\n",
    "\n",
    "To regularise our model, we add <a href=\"https://en.wikipedia.org/wiki/Dropout_(neural_networks)\">Dropout</a> layer. This layer randomy selected neurons and drop 30% of them out of the training process in order to avoid overfitting in our model.\n",
    "\n",
    "We are done! We were able to sucessfully create a CNN model architecture in just a few lines! you can see the model reperesnetion using summery instance:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 126, 126, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 62, 62, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 30, 30, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 14400)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1843328   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 1,854,370\n",
      "Trainable params: 1,854,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_classes =2\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3,3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_width, img_height, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (2, 2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (2, 2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Compiling the model</h4>\n",
    "\n",
    "Before we start traning our model, we need to sepcify learning process and the loss function. We configure these arguments by the \n",
    "compile method. We can also sepcify the evalution metric in the method. Here. we are going to use Adam optimizer, cross entropy as loss function and accuracy for our model evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Training</h4>\n",
    "\n",
    "Now it's time to train the model. This can be done by a single command in Keras. We are going to use fit_generator() method. If you are running your model on a GPU fit_generator is a better training method compared to fit() since it has higher efficiency. Fit_generator allows you to run parrel computations. So your CPU would be busy reading the data, doing the agumentation etc. while your GPU is being used to the model traning. If you are only using your CPU, you can use either fit or fit_generator.\n",
    "\n",
    "Now we need to declare the training arugments for our fitting method. The first argument train_generator which includes the training samples and labels. The next argument is step_per_epoch which is the number of batches of data we are going to use in each epoch and epoch is the number of iterations we are going to train the model. We configure the validation generator and validation_steps the same way for the validation data set. The next argument to set is verbose which sepcifies how you would like to see the training set progressing in each epoch:\n",
    "\n",
    "verbose = 0 : Shows nothing\n",
    "verbose = 1: Shows a progress bar for each epoch\n",
    "verbose = 2: Shows the number of epoch\n",
    "\n",
    "\n",
    "\n",
    "The next argument is the batch size – we don’t have to explicitly handle the batching up of our data during training in Keras, rather we just specify the batch size and it does it for us (I have a post on mini-batch gradient descent if this is unfamiliar to you).  In this case we are using a batch size of 128.  Next we pass the number of training epochs (10 in this case).  The verbose flag, set to 1 here, specifies if you want detailed information being printed in the console about the progress of the training.  During training, if verbose is set to 1, the following is output to the console:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " - 253s - loss: 0.6760 - acc: 0.5726 - val_loss: 0.6389 - val_acc: 0.6515\n",
      "Epoch 2/15\n",
      " - 285s - loss: 0.6318 - acc: 0.6478 - val_loss: 0.6106 - val_acc: 0.6604\n",
      "Epoch 3/15\n",
      " - 281s - loss: 0.6072 - acc: 0.6731 - val_loss: 0.5781 - val_acc: 0.7002\n",
      "Epoch 4/15\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch = len(X_train) // batch_size , \n",
    "                    validation_data=validation_generator, \n",
    "                    validation_steps= len(X_val) // batch_size, epochs=15, verbose=2 ,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
